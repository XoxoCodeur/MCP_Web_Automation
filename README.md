# MCP Web Automation - Test Technique Full Stack IA

Solution complÃ¨te d'automatisation web intelligente utilisant le Model Context Protocol (MCP) et l'intelligence artificielle pour le scraping adaptatif.

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Partie 1 : Serveur MCP](#partie-1--serveur-mcp)
- [Partie 2 : Agent de Scraping Intelligent](#partie-2--agent-de-scraping-intelligent)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Architecture](#architecture)
- [Documentation](#documentation)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une solution complÃ¨te d'automatisation web en deux parties :

1. **Serveur MCP** : Exposer 6 outils d'automatisation web (navigate, screenshot, extract_links, fill, click, get_html)
2. **Agent Intelligent** : Agent LLM capable d'extraire des donnÃ©es structurÃ©es depuis n'importe quelle page web selon un schÃ©ma JSON

### Technologies utilisÃ©es

- **Backend** : Python 3.11+
- **Automatisation** : Playwright
- **LLM** : OpenAI GPT-4o
- **Validation** : Pydantic
- **Protocole** : MCP (Model Context Protocol)

---

## ğŸ“¦ Partie 1 : Serveur MCP

### Outils exposÃ©s

Le serveur MCP expose 6 outils d'automatisation web :

| Outil | Description |
|-------|-------------|
| `navigate` | Naviguer vers une URL |
| `screenshot` | Capturer l'Ã©cran (viewport ou page complÃ¨te) |
| `extract_links` | Extraire tous les liens de la page |
| `fill` | Remplir un champ de formulaire |
| `click` | Cliquer sur un Ã©lÃ©ment |
| `get_html` | RÃ©cupÃ©rer le HTML complet post-JavaScript |

### Format de rÃ©ponse uniforme

```json
{
  "ok": true,
  "tool": "navigate",
  "session_id": "sess_abc123",
  "data": {"current_url": "https://example.com", "status": 200},
  "meta": {"ts": "2025-10-30T...", "duration_ms": 342}
}
```

### DÃ©mo Partie 1

```bash
python demo/scenario_part1.py
```

**ScÃ©nario** :
1. Naviguer vers https://example.com
2. Prendre une capture d'Ã©cran
3. Extraire tous les liens
4. Naviguer vers le premier lien externe
5. Capturer Ã  nouveau l'Ã©cran

---

## ğŸ¤– Partie 2 : Agent de Scraping Intelligent

### FonctionnalitÃ©s

L'agent utilise un LLM (GPT-4o) pour :
- âœ… Analyser automatiquement la structure HTML
- âœ… Identifier les sÃ©lecteurs CSS optimaux
- âœ… Extraire des donnÃ©es selon un schÃ©ma JSON
- âœ… GÃ©rer la pagination automatiquement
- âœ… Convertir les types (string â†’ number, boolean)
- âœ… GÃ©nÃ©rer un rapport de qualitÃ©

### Configuration exemple

```json
{
  "url": "https://books.toscrape.com/",
  "schema": {
    "products": [
      {
        "title": "string",
        "price": "number",
        "availability": "string",
        "rating": "string"
      }
    ],
    "metadata": {
      "date_extraction": "datetime",
      "nb_resultats": "number"
    }
  },
  "options": {
    "pagination": true,
    "max_pages": 3
  }
}
```

### DÃ©mo Partie 2

```bash
python demo/scenario_part2.py
```

**RÃ©sultat** : Fichier JSON structurÃ© avec donnÃ©es extraites + rapport de qualitÃ©

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- pip

### Ã‰tapes

```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/MCP_Web_Automation.git
cd MCP_Web_Automation

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Installer le navigateur Playwright
playwright install chromium

# 5. Configurer l'API OpenAI (pour Partie 2)
cp .env.example .env
# Ã‰diter .env et ajouter votre OPENAI_API_KEY
```

### Fichier .env

```bash
OPENAI_API_KEY=sk-...
```

---

## ğŸ’» Utilisation

### Serveur MCP (Partie 1)

```python
from src.mcp_server import MCPServer

server = MCPServer()
server.run()
```

### Agent de scraping (Partie 2)

#### API Python

```python
from src.scraping_agent import ScrapingAgent, ScrapingConfig
from src.mcp_server import ToolService

agent = ScrapingAgent(
    openai_api_key="sk-...",
    tool_service=ToolService()
)

config = ScrapingConfig(
    url="https://example.com/products",
    schema={
        "products": [{"name": "string", "price": "number"}]
    },
    options={"pagination": True, "max_pages": 5}
)

result = agent.scrape(config)
print(result.data)
```

#### CLI

```bash
python src/scraping_cli.py \
  --config config.json \
  --output results.json
```

---

## ğŸ—ï¸ Architecture

### Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent de Scraping Intelligent     â”‚
â”‚   (LLM + Orchestration)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Appels directs Python
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ToolService (MCP)              â”‚
â”‚  (navigate, click, get_html, etc.)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Playwright                  â”‚
â”‚    (Chromium automation)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pourquoi pas MCP complet (stdio/SSE) ?

Pour un agent Python utilisant des outils Python dans le mÃªme projet, l'approche **appels directs** est optimale :
- âœ… SimplicitÃ© de dÃ©veloppement
- âœ… Performance (pas d'overhead I/O)
- âœ… Gestion d'Ã©tat simplifiÃ©e
- âœ… Facile Ã  migrer vers MCP complet si besoin

Voir [DECISIONS_PART2.md](DECISIONS_PART2.md) pour les dÃ©tails architecturaux.

---

## ğŸ“š Documentation

### Fichiers de dÃ©cisions techniques

- **[DECISIONS.md](DECISIONS.md)** : DÃ©cisions Partie 1 (Serveur MCP)
- **[DECISIONS_PART2.md](DECISIONS_PART2.md)** : DÃ©cisions Partie 2 (Agent intelligent)

### Structure du projet

```
MCP_Web_Automation/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mcp_server.py          # Serveur MCP principal
â”‚   â”œâ”€â”€ scraping_agent.py      # Agent intelligent de scraping
â”‚   â”œâ”€â”€ scraping_cli.py        # Interface CLI pour l'agent
â”‚   â”œâ”€â”€ browser.py             # Gestionnaire de navigateur
â”‚   â”œâ”€â”€ errors.py              # Gestion d'erreurs
â”‚   â”œâ”€â”€ logging_conf.py        # Configuration logging
â”‚   â””â”€â”€ tools/                 # Outils MCP
â”‚       â”œâ”€â”€ navigate.py
â”‚       â”œâ”€â”€ screenshot.py
â”‚       â”œâ”€â”€ extract_links.py
â”‚       â”œâ”€â”€ fill.py
â”‚       â”œâ”€â”€ click.py
â”‚       â””â”€â”€ get_html.py
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ scenario_part1.py      # DÃ©mo Partie 1
â”‚   â””â”€â”€ scenario_part2.py      # DÃ©mo Partie 2
â”œâ”€â”€ DECISIONS.md               # DÃ©cisions techniques Partie 1
â”œâ”€â”€ DECISIONS_PART2.md         # DÃ©cisions techniques Partie 2
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ pyproject.toml             # Configuration projet
â””â”€â”€ README.md                  # Ce fichier
```

---

## ğŸ”§ DÃ©veloppement

### ExÃ©cuter les tests

```bash
# Partie 1
python demo/scenario_part1.py

# Partie 2
python demo/scenario_part2.py
```

### Logging

Les logs JSON sont Ã©crits sur stderr :

```json
{"level":"INFO","message":"tool_success","tool":"navigate","duration_ms":342}
```

---

## ğŸš§ Limitations connues

1. **Contexte LLM** : HTML tronquÃ© Ã  50KB
2. **CoÃ»t API** : Chaque page = 1 appel LLM
3. **Latence** : 2-5s par page (vs. scrapers traditionnels)
4. **Pagination scroll infini** : Non supportÃ©e
5. **Anti-bot** : Sites comme Amazon peuvent bloquer

Voir [DECISIONS_PART2.md](DECISIONS_PART2.md) section "Limitations" pour dÃ©tails.

---

## ğŸ”® Ã‰volutions futures

- [ ] Caching LLM pour pages similaires
- [ ] Support multi-LLM (Claude, Mistral, etc.)
- [ ] Outil `scroll` pour pagination infinie
- [ ] Stealth mode (user-agent, proxies)
- [ ] Authentication flows automatiques
- [ ] Rate limiting et respect robots.txt
- [ ] Monitoring Prometheus/Grafana

---

## ğŸ“„ Licence

Ce projet est un test technique rÃ©alisÃ© dans le cadre d'un processus de recrutement.

---

## ğŸ‘¤ Auteur

**Robin** - Test Technique Full Stack IA - Octobre 2025

---

## ğŸ™ Remerciements

- [Playwright](https://playwright.dev/) pour l'automatisation navigateur
- [OpenAI](https://openai.com/) pour l'API GPT-4o
- [Anthropic](https://www.anthropic.com/) pour le protocole MCP
