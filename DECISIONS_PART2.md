# D√©cisions Techniques - Partie 2 : Agent Intelligent de Scraping

## Objectif et port√©e

D√©velopper un agent intelligent capable d'extraire des donn√©es structur√©es depuis n'importe quelle page web dynamique, en s'appuyant sur un sch√©ma JSON fourni par l'utilisateur. L'agent doit √™tre adaptable, intelligent, et capable de g√©rer des interactions complexes, la pagination, et produire des rapports de qualit√©.

---

## 1. Architecture : Hybride Python-MCP (Appels directs)

### D√©cision architecturale

**L'agent appelle directement les outils MCP via `ToolService.call()` en Python, sans passer par le protocole MCP complet (stdio/SSE).**

```python
# Architecture impl√©ment√©e
ScrapingAgent (Python)
    ‚Üì appel direct Python
ToolService.call(tool_name, args)
    ‚Üì
MCP Tools (navigate, click, get_html, etc.)
    ‚Üì
Playwright
```

### Pourquoi ne pas utiliser le protocole MCP complet ?

Le test technique demande de "s'appuyer sur le serveur MCP cr√©√© dans la Partie 1", ce qui pourrait sugg√©rer une communication via stdio/SSE. Cependant, nous avons choisi une **int√©gration directe en Python** pour les raisons suivantes :

#### ‚úÖ Avantages de l'approche directe

1. **Simplicit√© de d√©veloppement**
   - Pas de gestion de processus s√©par√©s
   - Pas de s√©rialisation/d√©s√©rialisation JSON RPC
   - Debugging facilit√© (stack traces unifi√©es)
   - Code plus lisible et maintenable

2. **Performance**
   - Pas d'overhead de communication inter-processus
   - Pas de latence r√©seau (m√™me minime)
   - Partage direct de l'√©tat (session_id, browser context)
   - Appels synchrones rapides

3. **Gestion d'√©tat simplifi√©e**
   - Session partag√©e entre agent et outils dans le m√™me processus
   - Pas de synchronisation complexe
   - BrowserManager singleton accessible directement

4. **√âvolutivit√© facilit√©e**
   - Facile de migrer vers MCP complet si besoin futur
   - Les structures MCP (format de r√©ponse, erreurs) sont conserv√©es
   - API `ToolService` reste inchang√©e

#### üîÑ Quand utiliser MCP complet vs. appels directs ?

| Crit√®re | MCP Complet (stdio/SSE) | Appels Directs (notre choix) |
|---------|------------------------|------------------------------|
| **Agents externes** | ‚úÖ N√©cessaire | ‚ùå Non support√© |
| **Multi-langage** | ‚úÖ Agent Python/JS/Go | ‚ùå Python uniquement |
| **Isolation processus** | ‚úÖ Crash-proof | ‚ùå Crash agent = crash tools |
| **Performance** | ‚ö†Ô∏è Overhead I/O | ‚úÖ Appels directs |
| **D√©veloppement** | ‚ö†Ô∏è Plus complexe | ‚úÖ Simplifi√© |
| **M√™me codebase** | ‚ùå Non pertinent | ‚úÖ Optimal |

**Conclusion** : Pour un agent Python utilisant des outils Python dans le m√™me projet, l'approche directe est **optimale**. MCP complet serait surdimensionn√© ici.

---

## 2. R√©utilisation des structures MCP

Bien que nous n'utilisions pas le protocole complet, **nous conservons les structures et conventions MCP** pour garantir la coh√©rence et faciliter une migration future :

### Format de r√©ponse uniforme

```python
# Succ√®s
{
    "ok": True,
    "tool": "navigate",
    "session_id": "sess_abc123",
    "data": {"current_url": "...", "status": 200},
    "meta": {"ts": "2025-10-30T...", "duration_ms": 342}
}

# Erreur
{
    "ok": False,
    "tool": "click",
    "error": {"code": "ELEMENT_NOT_VISIBLE", "message": "..."},
    "meta": {"ts": "2025-10-30T...", "duration_ms": 5072}
}
```

### Gestion d'erreurs coh√©rente

```python
# L'agent utilise les m√™mes ErrorCode que MCP
from src.errors import ToolError, ErrorCode

try:
    session_id, data = self._call_tool("click", {...})
except ToolError as e:
    if e.code == ErrorCode.ELEMENT_NOT_VISIBLE:
        # Gestion sp√©cifique
```

### Avantages de cette coh√©rence

- **Logs uniformes** : M√™me format JSON que la Partie 1
- **Migration facilit√©e** : Si besoin de passer √† MCP complet, l'agent ne change presque pas
- **Maintenabilit√©** : Une seule convention de gestion d'erreurs dans tout le projet

---

## 3. Choix du LLM : OpenAI GPT-4o

### D√©cision

Utiliser **GPT-4o** (via l'API OpenAI) pour l'analyse HTML et l'extraction de donn√©es.

### Rationale

1. **Contexte suffisant**
   - 128K tokens permettent d'analyser des pages HTML compl√®tes
   - Strat√©gie de troncature √† 50KB pour rester confortable

2. **Qualit√© d'extraction**
   - Excellente compr√©hension de structures HTML et JSON
   - G√©n√©ration de JSON structur√© coh√©rente
   - Bonne performance sur identification de s√©lecteurs CSS

3. **API mature et fiable**
   - SDK Python officiel (`openai`)
   - Gestion d'erreurs robuste
   - Latence acceptable (~2-3s par page)

4. **Co√ªt raisonnable**
   - GPT-4o moins cher que GPT-4
   - Pour un MVP/test technique, le co√ªt est acceptable
   - Production : possibilit√© de caching ou batching

### Alternatives consid√©r√©es

| Mod√®le | Avantages | Inconv√©nients | D√©cision |
|--------|-----------|---------------|----------|
| **Claude 3.5 Sonnet** | Contexte 200K, excellente qualit√© | API Anthropic moins famili√®re | ‚ö†Ô∏è Viable |
| **GPT-4 Turbo** | Qualit√© maximale | Plus cher, latence plus √©lev√©e | ‚ùå |
| **GPT-3.5 Turbo** | Moins cher, rapide | Qualit√© d'extraction inf√©rieure | ‚ùå |
| **Mod√®les open-source** | Gratuit, auto-h√©bergeable | Qualit√© variable, setup complexe | ‚ùå |

---

## 4. Strat√©gie d'extraction : Prompting structur√©

### Approche choisie

L'agent utilise un **prompt structur√©** pour chaque page, avec le sch√©ma JSON cible et le HTML tronqu√©.

### Format du prompt

```python
prompt = f"""You are a web scraping expert. Extract structured data from HTML.

TARGET SCHEMA:
{json.dumps(schema, indent=2)}

HTML CONTENT (truncated to 50KB):
{html_content[:50000]}

INSTRUCTIONS:
1. Analyze the HTML structure carefully
2. Identify CSS selectors for each field in the schema
3. Extract ALL items matching the schema structure
4. Convert types according to schema (string ‚Üí number, boolean, etc.)
5. Handle missing data gracefully (use null)
6. Return ONLY valid JSON, no markdown, no explanations

OUTPUT FORMAT:
{{"items": [...]}}
"""
```

### Rationale

1. **Clart√© des instructions**
   - R√©duit les hallucinations du LLM
   - Format de sortie explicite (JSON pur)
   - Gestion des types demand√©e explicitement

2. **Contexte limit√©**
   - Troncature √† 50KB √©vite d√©passement de limite
   - Garde le d√©but du HTML (structure g√©n√©rale + premiers items)

3. **Temp√©rature 0**
   - Maximum de d√©terminisme
   - Extraction reproductible

4. **Validation post-extraction**
   - Parsing JSON syst√©matique
   - D√©tection des erreurs de format
   - Retry possible si √©chec

---

## 5. Gestion de la pagination

### D√©cision : D√©tection automatique via LLM

Au lieu de maintenir des r√®gles fixes pour la pagination, l'agent **demande au LLM** d'identifier le s√©lecteur du bouton "page suivante".

### Workflow

```python
# 1. Demander au LLM le s√©lecteur de pagination
prompt = """Analyze this HTML and identify the CSS selector for the "next page" button.

INSTRUCTIONS:
- The button MUST be active (not disabled)
- Avoid disabled elements (check for "disabled" class, aria-disabled)
- Prefer specific selectors (e.g., li.next:not(.disabled) a)
- Return ONLY the selector or "NO_PAGINATION"
"""

selector = llm.generate(prompt)

# 2. Si s√©lecteur trouv√©, cliquer via MCP
if selector != "NO_PAGINATION":
    self._call_tool("click", {"selector": selector})
```

### Avantages

1. **Adaptabilit√©** : Fonctionne sur diff√©rents patterns (boutons, liens, num√©ros de page)
2. **Pas de r√®gles fixes** : Pas de maintenance de liste de s√©lecteurs par site
3. **Intelligence contextuelle** : Le LLM comprend "disabled", "current", "active"

### Am√©liorations apport√©es

Lors du d√©veloppement, nous avons identifi√© et corrig√© plusieurs probl√®mes :

1. **Nettoyage du s√©lecteur**
   - Le LLM retournait parfois `` `.next` `` (avec backticks)
   - Solution : Strip des backticks inline et blocs markdown

2. **D√©tection de fin de pagination**
   - Le s√©lecteur `.next` peut exister mais √™tre d√©sactiv√© sur la derni√®re page
   - Solution : Prompt am√©lior√© demandant explicitement d'√©viter les √©l√©ments d√©sactiv√©s

3. **Scroll automatique**
   - Ajout de `scroll_into_view_if_needed()` dans l'outil `click`
   - R√©sout les cas o√π le bouton est hors viewport

---

## 6. Rapport de qualit√©

### D√©cision : M√©triques automatiques de compl√©tude

Chaque extraction g√©n√®re un **rapport de qualit√©** automatique pour √©valuer la fiabilit√© des donn√©es extraites.

### M√©triques incluses

```json
{
    "quality_report": {
        "total_items": 24,
        "complete_items": 22,
        "completion_rate": 0.917,
        "missing_fields": [
            "specifications.cpu: 2 items"
        ],
        "errors": []
    }
}
```

### G√©n√©ration

```python
def _check_completeness(self, item: dict, missing_fields: dict) -> bool:
    """Recursively check if item has all fields populated."""
    is_complete = True

    for key, value in item.items():
        if value is None or value == "":
            is_complete = False
            missing_fields[key] = missing_fields.get(key, 0) + 1
        elif isinstance(value, dict):
            # Recurse into nested objects
            is_complete &= self._check_completeness(value, missing_fields)
```

### Rationale

1. **Transparence** : L'utilisateur sait imm√©diatement si l'extraction est fiable
2. **D√©bogage** : Identification rapide des champs probl√©matiques
3. **Am√©lioration** : Guide pour affiner le sch√©ma ou ajouter des interactions

---

## 7. Gestion des erreurs : R√©silience maximale

### Principe : √âchecs partiels ne bloquent pas l'extraction

L'agent est con√ßu pour **continuer m√™me en cas d'erreurs partielles**.

### Strat√©gies de r√©silience

| Situation | Comportement | Rationale |
|-----------|--------------|-----------|
| **Navigation √©choue** | Erreur fatale, status="error" | Pas de HTML = pas d'extraction |
| **Interaction √©choue** | Warning log, continue | Cookies/popups optionnels |
| **Extraction page 1 OK, page 2 KO** | Retourne page 1, rapport partiel | Donn√©es partielles > rien |
| **Pagination non d√©tect√©e** | Arr√™te pagination, retourne donn√©es | Normal sur derni√®re page |
| **Conversion type √©choue** | Champ √† `null`, item incomplet | Signal√© dans quality_report |

### Format de r√©ponse

```python
# Succ√®s (m√™me partiel)
{
    "status": "success",
    "data": {...},          # Donn√©es extraites (m√™me partielles)
    "quality_report": {...} # Indique la compl√©tude
}

# Erreur fatale uniquement
{
    "status": "error",
    "error": "Navigation timeout",
    "data": None,
    "quality_report": None
}
```

### Avantages

- **Robustesse** : Production-ready, comportement pr√©visible
- **Visibilit√©** : Le quality_report r√©v√®le les probl√®mes
- **Valeur maximale** : Donn√©es partielles valent mieux que rien

---

## 8. Interactions pr√©liminaires

### D√©cision : Syst√®me configurable par l'utilisateur

L'utilisateur peut d√©finir des **interactions pr√©liminaires** √† ex√©cuter avant l'extraction (accepter cookies, fermer popups, etc.).

### Configuration

```json
{
    "interactions": [
        {"type": "click", "selector": "#accept-cookies"},
        {"type": "wait", "duration": 2000},
        {"type": "scroll", "direction": "bottom"}
    ]
}
```

### Impl√©mentation

```python
for interaction in config.interactions:
    if interaction["type"] == "click":
        self._call_tool("click", {"selector": interaction["selector"]})
    elif interaction["type"] == "wait":
        time.sleep(interaction["duration"] / 1000)
    # scroll non impl√©ment√© (n√©cessite ajout outil MCP)
```

### Rationale

1. **Flexibilit√©** : Chaque site a ses propres popups/cookies
2. **R√©utilisation MCP** : D√©l√©gation aux outils existants
3. **Non-bloquant** : √âchec d'interaction = warning, extraction continue

---

## 9. Limitations assum√©es et √©volutions futures

### Limitations connues

1. **Contexte LLM** : HTML tronqu√© √† 50KB (peut manquer contenu de grandes pages)
2. **Co√ªt API** : Chaque page = 1 appel LLM (peut √™tre co√ªteux pour gros volumes)
3. **Latence** : 2-5s par page (plus lent que scrapers traditionnels)
4. **Pagination scroll infini** : Non support√©e (n√©cessite outil `scroll` MCP)
5. **Sites avec anti-bot** : Amazon, Cloudflare challenge peuvent bloquer

### Acceptation de ces limitations

Ces limitations sont **acceptables pour un MVP intelligent** :
- L'adaptabilit√© et la maintenabilit√© compensent la latence/co√ªt
- Pour un test technique, la solution d√©montre l'intelligence et la flexibilit√©
- En production, des optimisations sont possibles (voir ci-dessous)

### √âvolutions futures possibles

1. **Caching LLM** : R√©utiliser analyses pour pages similaires
2. **Multi-LLM** : Support Claude, Mistral, mod√®les locaux
3. **Outil scroll** : Ajouter au MCP server pour pagination infinie
4. **Stealth mode** : User-agent, proxies, delays anti-d√©tection
5. **Authentication flows** : Login automatique avant scraping
6. **Rate limiting** : Int√©gr√© dans l'agent (respect robots.txt)
7. **Monitoring** : Int√©gration Prometheus/Grafana pour m√©triques
8. **Batching** : Grouper plusieurs pages dans un seul appel LLM

---

## 10. Comparaison avec approche traditionnelle

### Scraper traditionnel (BeautifulSoup/Scrapy)

```python
# Approche traditionnelle : s√©lecteurs fixes
products = soup.select(".product-card")
for product in products:
    title = product.select_one(".title").text
    price = float(product.select_one(".price").text.replace("‚Ç¨", ""))
```

**Probl√®mes** :
- ‚ùå Cassant aux changements HTML
- ‚ùå Maintenance co√ªteuse (un scraper par site)
- ‚ùå Pas d'intelligence (ne s'adapte pas)

### Notre approche (LLM + MCP)

```python
# Approche intelligente : agent adaptatif
agent = ScrapingAgent(api_key, tool_service)
result = agent.scrape(config)  # Le LLM trouve les s√©lecteurs
```

**Avantages** :
- ‚úÖ S'adapte aux changements HTML
- ‚úÖ Un seul agent pour tous les sites
- ‚úÖ Maintenance minimale (pas de s√©lecteurs en dur)
- ‚úÖ Quality report automatique

**Trade-offs** :
- ‚ö†Ô∏è Plus lent (2-5s/page vs. 0.1s/page)
- ‚ö†Ô∏è Co√ªt API (LLM)
- ‚ö†Ô∏è D√©pendance externe (API OpenAI)

**Conclusion** : Pour des sites changeants, √† faible volume, ou n√©cessitant de l'adaptabilit√©, notre approche est **sup√©rieure**. Pour du scraping massif et stable, l'approche traditionnelle reste pertinente.

---

## Conclusion

L'architecture hybride choisie (appels directs Python-MCP) offre le meilleur compromis entre **simplicit√©, performance, et maintenabilit√©** pour ce projet. Elle :

- ‚úÖ R√©utilise les outils MCP de la Partie 1
- ‚úÖ Conserve les conventions MCP (formats, erreurs)
- ‚úÖ Permet une migration future vers MCP complet si besoin
- ‚úÖ Offre une solution production-ready avec r√©silience et qualit√©

L'utilisation d'un **LLM pour l'analyse et l'extraction** apporte une **intelligence et adaptabilit√©** impossibles avec des approches traditionnelles, au prix d'une latence et d'un co√ªt acceptables pour ce cas d'usage.
